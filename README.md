# 深度学习炼丹术实践之姿态识别

其实我一直都有一个神奇的想法: 通过炼丹术识别用户的动作, 我管它叫做姿态识别.

要达到姿态识别的功能, 简单分析就可以知道, 需要用摄像头实时拍摄一个人的动作, 并把它传输去PC端, 然后用炼丹术把数据映射成为一个简单的动作.

(可以看作是一个简单的分类器)

## 安卓端

我发现华为的 MindSpore 有一个很适合的功能, PoseNet. 我可以通过 PoseNet 来简化输入的数据, 以达到数据集更小, 特征性更强的效果, 即用 PoseNet 来做特征工程.

听了一次华为在南大的讲座之后, 我下载了 MindSpore 开放的源码, 找到了 PoseNet 的模块, 并顺利通过了编译.

经过一系列的改造, 我给 PoseNet 加入了网络模块, 并将 PoseNet 获取到的数据转化成 Json, 并用 POST 方法传输到 PC 端中. 所以我们只要在 PC 端开一个服务器就能接受到数据.

这个魔改版本的 PoseNet 被我更名为 PoseKey, 源码已经上传到 [GitHub](https://github.com/OrangeX4/PoseKey-Android).

只要在同一个 WiFi 即同一个局域网下, 在里面写上你的 PC 的 IP 地址, 它在识别到用户的姿态之后, 就会自动传输数据到 PC 的 Server 上.

Json 样例如下:

```json
{
    "test": "android",
    "score": 0.8146785497665405,
    "time": 1608909337572,
    "keyPoints": {
        "NOSE": {
            "score": 0.815959095954895,
            "position": {
                "x": 127,
                "y": 88
            }
        },
        "LEFT_EYE": {
            "score": 0.7012987732887268,
            "position": {
                "x": 128,
                "y": 85
            }
        },
        "RIGHT_EYE": {
            "score": 0.5838527679443359,
            "position": {
                "x": 127,
                "y": 85
            }
        },
        "LEFT_EAR": {
            "score": 0.8103403449058533,
            "position": {
                "x": 131,
                "y": 86
            }
        },
        "RIGHT_EAR": {
            "score": 0.5026875734329224,
            "position": {
                "x": 130,
                "y": 85
            }
        },
        "LEFT_SHOULDER": {
            "score": 0.9689308404922485,
            "position": {
                "x": 127,
                "y": 101
            }
        },
        "RIGHT_SHOULDER": {
            "score": 0.9753607511520386,
            "position": {
                "x": 131,
                "y": 100
            }
        },
        "LEFT_ELBOW": {
            "score": 0.8243715167045593,
            "position": {
                "x": 111,
                "y": 120
            }
        },
        "RIGHT_ELBOW": {
            "score": 0.6323183178901672,
            "position": {
                "x": 155,
                "y": 119
            }
        },
        "LEFT_WRIST": {
            "score": 0.7550386190414429,
            "position": {
                "x": 110,
                "y": 137
            }
        },
        "RIGHT_WRIST": {
            "score": 0.5845995545387268,
            "position": {
                "x": 126,
                "y": 136
            }
        },
        "LEFT_HIP": {
            "score": 0.9933162927627563,
            "position": {
                "x": 124,
                "y": 135
            }
        },
        "RIGHT_HIP": {
            "score": 0.9925392866134644,
            "position": {
                "x": 130,
                "y": 136
            }
        },
        "LEFT_KNEE": {
            "score": 0.9693067073822021,
            "position": {
                "x": 131,
                "y": 159
            }
        },
        "RIGHT_KNEE": {
            "score": 0.9470896124839783,
            "position": {
                "x": 126,
                "y": 159
            }
        },
        "LEFT_ANKLE": {
            "score": 0.9394081234931946,
            "position": {
                "x": 128,
                "y": 179
            }
        },
        "RIGHT_ANKLE": {
            "score": 0.853115975856781,
            "position": {
                "x": 123,
                "y": 179
            }
        }
    }
}
```


APP 效果如图:

![](https://s3.ax1x.com/2020/12/27/r5M0O0.jpg)


## PC端

### 数据记录

经过尝试, 我用 Python 开启了一个 Flask, 并将数据处理成一个 numpy 数组, 并尝试去做一个最简单的二分: 站立 (STAND) 或 跑步 (RUN).

我自己记录和标注数据, 真就移动端+前端+后端+数据的全栈工具人呗.

于是顶着被室友当傻子看的风险, 我在宿舍时而呆若木鸡, 时而动若疯兔, 录了接近十分钟的数据.

对于这些数据的存储与处理, 我选择不使用数据库, 而是作为伪json文件保存下来, 最终结果大概是两万行的数据量. 经过一番处理, 变成了700×24×17×3的训练集和100×24×17×3的测试集.

3是指其中一个点的分数, x坐标和y坐标.

17是指一共17个的关键点 (手臂啊, 肩膀啊什么的).

24是指24行的数据, 大概对应着一秒钟之内产生的数据, 即加入了一个类似时间变化的维度.

(700+100)×24=19200, 即大概两万行的数据.

记录数据的时候各种出 Bug, 特别是 Python 的 IO 操作还可能导致出现空行, 因此我不得不手动清除空行. 打算之后再写一个自动去除空行的小工具.

### 数据处理

头一次使用上了 Google 的 Colab, 体验还是蛮不错的, 用来跑一些简单的训练很快乐. (至少比我这个算力极弱还是 AMD 的弱鸡轻薄本好太多了)

但结果并不一定完全如人所愿, 事实上就算是这个简单的二分, 效果也不是很好. 不知道是 Model 设计不佳还是过拟合的缘故, 在跑测试集的时候效果很好, 但是到真正实际用到的时候, 甚至跑不过随机!

### 实际尝试

跑好了模型之后, 我开始尝试实时识别我的动作. 但结果是, 我必须站在一个独特的位置效果才会好, 站在其他位置, 基本都被识别成了 RUN.

看来就算是一个简单的二分, 也不是那么好做的啊.

现在只是进行着想法论证, 还远远没到出成品的时候. 成品需要的是多分类, 而不是二分类, 想想就头疼, 唉.

附一张勉强算是成功的截图:

![](https://s3.ax1x.com/2020/12/27/r5Mwyq.png)

[GitHub](https://github.com/OrangeX4/PoseKey-Desktop)